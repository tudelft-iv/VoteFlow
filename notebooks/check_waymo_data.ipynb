{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import pickle\n",
    "import os \n",
    "os.chdir('/home/shimingwang/workspace/sf_tv/sceneflow_tv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = 'data/waymo_open_dataset_scene_flow/preprocess_v2/train'\n",
    "file_name = 'index_total.pkl'\n",
    "file_path = os.path.join(data_root, file_name)\n",
    "\n",
    "total_index = pickle.load(open(file_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 155687/155687 [00:19<00:00, 8086.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['2088865281951278665_4460_000_4480_000', '1553535058789636'], ['2088865281951278665_4460_000_4480_000', '1553535058889616'], ['2088865281951278665_4460_000_4480_000', '1553535059489540'], ['2088865281951278665_4460_000_4480_000', '1553535061389604'], ['2088865281951278665_4460_000_4480_000', '1553535061489589'], ['2088865281951278665_4460_000_4480_000', '1553535062189579'], ['2088865281951278665_4460_000_4480_000', '1553535062289602'], ['2088865281951278665_4460_000_4480_000', '1553535062389615'], ['2088865281951278665_4460_000_4480_000', '1553535062489637'], ['2088865281951278665_4460_000_4480_000', '1553535062589656'], ['2088865281951278665_4460_000_4480_000', '1553535062689646'], ['2088865281951278665_4460_000_4480_000', '1553535062789669'], ['2088865281951278665_4460_000_4480_000', '1553535062889647'], ['2088865281951278665_4460_000_4480_000', '1553535062989672'], ['2088865281951278665_4460_000_4480_000', '1553535063089655'], ['2088865281951278665_4460_000_4480_000', '1553535063189676'], ['2088865281951278665_4460_000_4480_000', '1553535063289654'], ['2088865281951278665_4460_000_4480_000', '1553535063389641'], ['2088865281951278665_4460_000_4480_000', '1553535063489629'], ['2088865281951278665_4460_000_4480_000', '1553535063589616'], ['2088865281951278665_4460_000_4480_000', '1553535063789591'], ['2088865281951278665_4460_000_4480_000', '1553535065289561'], ['2088865281951278665_4460_000_4480_000', '1553535065989545'], ['15367782110311024266_2103_310_2123_310', '1516410981471180'], ['15367782110311024266_2103_310_2123_310', '1516410981871238'], ['15367782110311024266_2103_310_2123_310', '1516410981971254'], ['15367782110311024266_2103_310_2123_310', '1516410982471129'], ['15367782110311024266_2103_310_2123_310', '1516410982571085'], ['15367782110311024266_2103_310_2123_310', '1516410982671104'], ['15367782110311024266_2103_310_2123_310', '1516410982771093'], ['15367782110311024266_2103_310_2123_310', '1516410982871081'], ['15367782110311024266_2103_310_2123_310', '1516410982971073'], ['15367782110311024266_2103_310_2123_310', '1516410983071096']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "no_lable_list = []\n",
    "for idx in tqdm(range(len(total_index))):\n",
    "    scene_id, timestamp = total_index[idx]\n",
    "    key = str(timestamp)\n",
    "    with h5py.File(os.path.join(data_root, f'{scene_id}.h5'), 'r') as f:\n",
    "        # print(f[key].keys())\n",
    "        if 'label' not in f[key].keys():\n",
    "            no_lable_list.append([scene_id, timestamp])\n",
    "print(no_lable_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "print(len(no_lable_list))\n",
    "for no_label_sample in no_lable_list:\n",
    "    scene_id, timestamp = no_label_sample\n",
    "    # print(scene_id, timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset import HDF5Dataset, collate_fn_pad\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = HDF5Dataset(data_root, n_frames=2, dufo=True)\n",
    "train_data = DataLoader(train_dataset,\n",
    "                        batch_size=1,\n",
    "                        shuffle=True,\n",
    "                        num_workers=8,\n",
    "                        collate_fn=collate_fn_pad,\n",
    "                        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6407it [00:26, 240.52it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "Caught KeyError in DataLoader worker process 7.\nOriginal Traceback (most recent call last):\n  File \"/home/shimingwang/miniconda3/envs/sf_tv/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/shimingwang/miniconda3/envs/sf_tv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/shimingwang/miniconda3/envs/sf_tv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/shimingwang/workspace/sf_tv/sceneflow_tv/src/dataset.py\", line 197, in __getitem__\n    res_dict['pc0_dynamic'] = torch.tensor(f[key]['label'][:].astype('int16'))\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n  File \"/home/shimingwang/miniconda3/envs/sf_tv/lib/python3.8/site-packages/h5py/_hl/group.py\", line 357, in __getitem__\n    oid = h5o.open(self.id, self._e(name), lapl=self._lapl)\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n  File \"h5py/h5o.pyx\", line 241, in h5py.h5o.open\nKeyError: \"Unable to synchronously open object (object 'label' doesn't exist)\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, data \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(train_data)):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/sf_tv/lib/python3.8/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/sf_tv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/sf_tv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sf_tv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/sf_tv/lib/python3.8/site-packages/torch/_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 644\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mKeyError\u001b[0m: Caught KeyError in DataLoader worker process 7.\nOriginal Traceback (most recent call last):\n  File \"/home/shimingwang/miniconda3/envs/sf_tv/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/shimingwang/miniconda3/envs/sf_tv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/shimingwang/miniconda3/envs/sf_tv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/shimingwang/workspace/sf_tv/sceneflow_tv/src/dataset.py\", line 197, in __getitem__\n    res_dict['pc0_dynamic'] = torch.tensor(f[key]['label'][:].astype('int16'))\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n  File \"/home/shimingwang/miniconda3/envs/sf_tv/lib/python3.8/site-packages/h5py/_hl/group.py\", line 357, in __getitem__\n    oid = h5o.open(self.id, self._e(name), lapl=self._lapl)\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n  File \"h5py/h5o.pyx\", line 241, in h5py.h5o.open\nKeyError: \"Unable to synchronously open object (object 'label' doesn't exist)\"\n"
     ]
    }
   ],
   "source": [
    "for idx, data in tqdm(enumerate(train_data)):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check waymo validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import pickle\n",
    "import os \n",
    "os.chdir('/home/shimingwang/workspace/sf_tv/sceneflow_tv')\n",
    "\n",
    "from src.trainer import ModelWrapper\n",
    "import hydra\n",
    "from hydra.core.hydra_config import HydraConfig\n",
    "import omegaconf \n",
    "from omegaconf import OmegaConf, DictConfig, ListConfig\n",
    "from src.dataset import HDF5Dataset, collate_fn_pad\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = HDF5Dataset('data/waymo_open_dataset_scene_flow/preprocess/valid', #\"/val\", \n",
    "                n_frames=2,\n",
    "                )\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "collate_fn=collate_fn_pad,\n",
    "pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'logs/jobs/sf_voxel_model_m_16_n_128_ep_12_lr_0.0002_bs_10_use_gru_decoder_m_16_n_128_4_a100_new_fine_tune_ep6/11-09-15-01/checkpoints/last.ckpt'\n",
    "config_path = 'conf/eval.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/jobs/sf_voxel_model_m_16_n_128_ep_12_lr_0.0002_bs_10_use_gru_decoder_m_16_n_128_4_a100_new_fine_tune_ep6/11-09-15-01/checkpoints/last.ckpt\n",
      "{'name': 'sf_voxel_model', 'target': {'_target_': 'src.models.SFVoxelModel', 'nframes': 1, 'm': 16, 'n': 128, 'input_channels': 32, 'output_channels': 64, 'point_cloud_range': [-51.2, -51.2, -3, 51.2, 51.2, 3], 'voxel_size': [0.2, 0.2, 6], 'grid_feature_size': [512, 512, 1], 'decoder': 'gru_decoder', 'decoder_layers': 1, 'use_bn_in_vol': True, 'use_ball_query': False, 'vol_conv_hidden_dim': 16}, 'val_monitor': 'val/Dynamic/Mean', 'exp_id': 'sf_voxel_model_m_16_n_128'}\n"
     ]
    }
   ],
   "source": [
    "cfg = OmegaConf.load(config_path)\n",
    "cfg.update(checkpoint=checkpoint_path)\n",
    "print(cfg.checkpoint)\n",
    "torch_load_ckpt = torch.load(cfg.checkpoint)\n",
    "checkpoint_params = DictConfig(torch_load_ckpt[\"hyper_parameters\"])\n",
    "print(checkpoint_params.cfg.model)\n",
    "# print(cfg.defaults.model)\n",
    "cfg.update(model=checkpoint_params.cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In wrapper:  <class 'omegaconf.dictconfig.DictConfig'>\n",
      "n x/y/z:  22 22 2\n",
      "search window radius in target pc: 11\n",
      "using decoder: gru_decoder\n",
      "using knn, m=16, n=128\n",
      "gru decoder: GRUDecoder(\n",
      "  (offset_encoder): Linear(in_features=3, out_features=64, bias=True)\n",
      "  (proj_head): Sequential(\n",
      "    (0): Linear(in_features=192, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (gru): ConvGRU(\n",
      "    (convz): Linear(in_features=192, out_features=128, bias=True)\n",
      "    (convr): Linear(in_features=192, out_features=128, bias=True)\n",
      "    (convq): Linear(in_features=192, out_features=128, bias=True)\n",
      "    (sigmoid): Sigmoid()\n",
      "    (tanh): Tanh()\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=192, out_features=32, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Linear(in_features=32, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mymodel = ModelWrapper.load_from_checkpoint(cfg.checkpoint, cfg=cfg, eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_cuda(batch):\n",
    "    for key in batch.keys():\n",
    "        if isinstance(batch[key], torch.Tensor):\n",
    "            batch[key] = batch[key].cuda()\n",
    "        elif isinstance(batch[key], list):\n",
    "            batch[key][0] = batch[key][0].cuda()\n",
    "        else:\n",
    "            raise ValueError\n",
    "    return batch    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29462it [05:28, 86.09it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error catched for idx: 29457\n",
      "error in im2ht_gpu_kernel: invalid configuration argument\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39381it [14:57, 43.90it/s]\n"
     ]
    }
   ],
   "source": [
    "index = 29457\n",
    "error_list = []\n",
    "mymodel.model = mymodel.model.cuda()\n",
    "for idx, batch in tqdm(enumerate(val_loader)):\n",
    "    if idx >= index:\n",
    "        batch = batch_cuda(batch)\n",
    "        try:\n",
    "            res_dict = mymodel.model(batch)\n",
    "        except:\n",
    "            error_list.append((idx, batch))\n",
    "            print('Error catched for idx:', idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pc0', 'pc1', 'pose0', 'pose1', 'flow', 'flow_is_valid', 'flow_category_indices', 'ego_motion'])\n",
      "pc0 torch.Size([1, 1248, 3])\n",
      "pc1 torch.Size([1, 895, 3])\n",
      "pose0 torch.Size([4, 4])\n",
      "pose1 torch.Size([4, 4])\n",
      "flow torch.Size([1, 1248, 3])\n",
      "flow_is_valid torch.Size([1, 1248])\n",
      "flow_category_indices torch.Size([1, 1248])\n",
      "ego_motion torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "print(batch.keys())\n",
    "for key in batch.keys():\n",
    "    if isinstance(batch[key], torch.Tensor):\n",
    "        print(key, batch[key].shape)\n",
    "    elif isinstance(batch[key], list):\n",
    "        print(key, batch[key][0].shape)\n",
    "    else:\n",
    "        raise ValueError"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sf_tv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
