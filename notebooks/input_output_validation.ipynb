{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "os.chdir('/home/shimingwang/workspace/sf_tv/sceneflow_tv_se')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'outputs/vis_batch.pkl'\n",
    "vis_batch = pickle.load(open(file_name, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['inputs', 'outputs'])\n"
     ]
    }
   ],
   "source": [
    "print(vis_batch.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pc0', 'pc1', 'pose0', 'pose1', 'flow', 'flow_is_valid', 'flow_category_indices', 'ego_motion'])\n",
      "pc0 tensor torch.Size([2, 82685, 3])\n",
      "pc1 tensor torch.Size([2, 82760, 3])\n",
      "pose0 list 2 torch.Size([4, 4])\n",
      "pose1 list 2 torch.Size([4, 4])\n",
      "flow tensor torch.Size([2, 82685, 3])\n",
      "flow_is_valid tensor torch.Size([2, 82685])\n",
      "flow_category_indices tensor torch.Size([2, 82685])\n",
      "ego_motion list 2 torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = vis_batch['inputs']\n",
    "print(inputs.keys())\n",
    "\n",
    "for key in inputs.keys():\n",
    "    if isinstance(inputs[key], torch.Tensor):\n",
    "        print(key, 'tensor', inputs[key].shape)\n",
    "    if isinstance(inputs[key], list):\n",
    "        print(key, 'list', len(inputs[key]), inputs[key][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pkl = 'data/Argoverse2_demo/preprocess_v2/sensor/val/index_eval.pkl'\n",
    "\n",
    "file = open(eval_pkl, 'rb')\n",
    "\n",
    "index_eval = pickle.load(file)\n",
    "\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "2\n",
      "<class 'str'> 36\n",
      "25e5c600-36fe-3245-9cc0-40ef91620c22\n"
     ]
    }
   ],
   "source": [
    "print(len(index_eval))\n",
    "print(len(index_eval[0]))\n",
    "print(type(index_eval[0][0]), len(index_eval[0][0]))\n",
    "print(index_eval[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pkl = 'data/Argoverse2_demo/preprocess_v2/sensor/val/index_total.pkl'\n",
    "\n",
    "file = open(total_pkl, 'rb')\n",
    "\n",
    "index_total = pickle.load(file)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n"
     ]
    }
   ],
   "source": [
    "print(len(index_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_num_channels: int, out_num_channels: int,\n",
    "                 kernel_size=3, stride=1, padding=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_num_channels, out_num_channels, kernel_size, stride, padding, bias=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv(x)\n",
    "        x = F.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6400, 20, 20])\n",
      "torch.Size([6400, 64, 10, 10])\n",
      "torch.Size([6400, 64, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 6400, 20, 20)\n",
    "print(input.shape)\n",
    "hidden_dim = 64\n",
    "conv1 = ConvBlock(in_num_channels=1, out_num_channels=hidden_dim, stride=2)\n",
    "maxpool = nn.MaxPool2d(2)    \n",
    "\n",
    "x1 = conv1(input.view(1*6400, 1, 20, 20))\n",
    "print(x1.shape)\n",
    "x2 = maxpool(x1)\n",
    "print(x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([71854, 192, 1])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(71854, 192, 1)\n",
    "cond1d = nn.linear(192, 192)\n",
    "\n",
    "output = cond1d(input)\n",
    "\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sf_tv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
